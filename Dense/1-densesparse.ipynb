{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a129598",
   "metadata": {},
   "source": [
    "## Hybrid Retriever- Combining Dense And Sparse Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f518da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c86da13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\RAGUdemy\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain helps build LLM applications.\"),\n",
    "    Document(page_content=\"Pinecone is a vector database for semantic search.\"),\n",
    "    Document(page_content=\"The Eiffel Tower is located in Paris.\"),\n",
    "    Document(page_content=\"Langchain can be used to develop agentic ai application.\"),\n",
    "    Document(page_content=\"Langchain has many types of retrievers.\")\n",
    "]\n",
    "\n",
    "# Step 2: Dense Retriever (FAISS + HuggingFace)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "dense_vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "dense_retriever = dense_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76569a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sparse Retriever(BM25)\n",
    "sparse_retriever=BM25Retriever.from_documents(docs)\n",
    "sparse_retriever.k=3 ##top- k documents to retriever\n",
    "\n",
    "## step 4 : Combine with Ensemble Retriever\n",
    "hybrid_retriever=EnsembleRetriever(\n",
    "    retrievers=[dense_retriever,sparse_retriever],\n",
    "    weight=[0.7,0.3]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d59933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002227A2DFA10>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000002227A5A9A90>, k=3)], weights=[0.5, 0.5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec3b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Document 1:\n",
      "LangChain helps build LLM applications.\n",
      "\n",
      "ðŸ”¹ Document 2:\n",
      "Langchain can be used to develop agentic ai application.\n",
      "\n",
      "ðŸ”¹ Document 3:\n",
      "Langchain has many types of retrievers.\n",
      "\n",
      "ðŸ”¹ Document 4:\n",
      "Pinecone is a vector database for semantic search.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Query and get results\n",
    "query = \"How can I build an application using LLMs?\"\n",
    "results = hybrid_retriever.invoke(query)\n",
    "\n",
    "# Step 6: Print results\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nðŸ”¹ Document {i+1}:\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c57cb",
   "metadata": {},
   "source": [
    "### RAG Pipeline with hybrid retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf22afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e17a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002237E1BE710>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002237E1BEC10>, root_client=<openai.OpenAI object at 0x000002237E1BDE50>, root_async_client=<openai.AsyncOpenAI object at 0x000002237E1BE5D0>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Prompt Template\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "## step 6-llm\n",
    "llm=init_chat_model(\"openai:gpt-3.5-turbo\",temperature=0.2)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9eb55e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002227A2DFA10>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000002227A5A9A90>, k=3)], weights=[0.5, 0.5]), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAnswer the question based on the context below.\\n\\nContext:\\n{context}\\n\\nQuestion: {input}\\n')\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002237E1BE710>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002237E1BEC10>, root_client=<openai.OpenAI object at 0x000002237E1BDE50>, root_async_client=<openai.AsyncOpenAI object at 0x000002237E1BE5D0>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create stuff Docuemnt Chain\n",
    "document_chain=create_stuff_documents_chain(llm=llm,prompt=prompt)\n",
    "\n",
    "## create Full rAg chain\n",
    "rag_chain=create_retrieval_chain(retriever=hybrid_retriever,combine_docs_chain=document_chain)\n",
    "rag_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb2441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Answer:\n",
      " You can build an app using LLMs by utilizing LangChain, which helps in developing LLM applications. LangChain can be used to develop agentic AI applications, and it offers various types of retrievers to enhance the functionality of your app. Additionally, you can also consider using Pinecone, a vector database for semantic search, to further improve the performance of your LLM-based app.\n",
      "\n",
      "ðŸ“„ Source Documents:\n",
      "\n",
      "Doc 1: LangChain helps build LLM applications.\n",
      "\n",
      "Doc 2: Langchain can be used to develop agentic ai application.\n",
      "\n",
      "Doc 3: Langchain has many types of retrievers.\n",
      "\n",
      "Doc 4: Pinecone is a vector database for semantic search.\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Ask a question\n",
    "query = {\"input\": \"How can I build an app using LLMs?\"}\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "# Step 10: Output\n",
    "print(\"âœ… Answer:\\n\", response[\"answer\"])\n",
    "\n",
    "print(\"\\nðŸ“„ Source Documents:\")\n",
    "for i, doc in enumerate(response[\"context\"]):\n",
    "    print(f\"\\nDoc {i+1}: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4468a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a58760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41501b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99604bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
